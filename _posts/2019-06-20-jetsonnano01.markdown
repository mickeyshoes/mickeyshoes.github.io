---
layout: post
title:  "Jetson Nano를 이용한 물체인식 코드 돌려보기"
date:   2019-06-20 23:15:00
last_modified_at:  2019-06-20 23:15:00
excerpt: "구조부터 한번 찬찬히 살펴보자. 주로 사용했던 부분위주로 설명하겠다. 1번은 SD카드에 운영체제를 설치하여 넣어주면 된다. 4번은 랜 포트 5번은 USB 포트이다...."
categories: lab
tags:  Jetson Nano
image:
  feature: mcikey-OpryHouse.jpg
  topPosition: 0px
bgContrast: dark
bgGradientOpacity: darker
syntaxHighlighter: no
---


Set up
--


#### 구조
***
<div class="img img--fullContainer img--14xLeading" style="background-image: url({{ site.baseurl_posts_img }}jetson-nano-dev-kit-top-r6-HR.png);"></div>

사진 출처 - https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#intro

구조부터 한번 찬찬히 살펴보자.

주로 사용했던 부분위주로 설명하겠다.

1번은 SD카드에 운영체제를 설치하여 넣어주면 된다.

4번은 랜 포트

5번은 USB 포트이다. 작성자는 키보드와 마우스, 무선랜카드를 장착해서 사용했다.

6번에는 모니터를 연결하여 사용

8번은 jetson nano 충전기를 연결

9번은 라즈베리파이 카메라를 연결하는 포트이다.

구조에 대한 설명이 끝났다. 이제 본격적인 setting에 들어가보자

#### Setting
***
일단 운영체제를 먼저 설치해야 한다.

ubuntu를 사용해서 Jetson Nano를 실행해보자.

일단 SD카드를 포맷부터 해야한다.

다운로드는 하단 링크 참조.

[윈도우](https://www.sdcard.org/downloads/formatter/eula_windows/)

[MAC, LINUX](https://www.balena.io/etcher/)

그 다음 공식홈페이지에서 Jetson Nano에 쓰일 SD Card에 image 파일을 받아와야 한다.

직접 nvidia 공식홈페이지에서 다운로드를 받아도 되고 하단의 링크에서 다운로드 받아도 된다.

용량이 꽤나 큰 편이니 주의하자.

[Jetson Nano Developer Kit SD Card Image](https://developer.nvidia.com/embedded/dlc/jetson-nano-dev-kit-sd-card-image)

다운로드가 완료 되었다면 SD카드에 파일을 넣고 Jetson의 2번 포트에 넣어주자

Jetson을 다루기 위해 모니터, 마우스, 무선랜포트 or 랜선, 전원을 연결하고 실행시킨다.

실행시키면 ubuntu 설치가 이루어 질 것이다.

운영체제 설치가 완료되면 이제 Jetson을 동작시켜보자 !

참고한 동영상 : [친절한 언박싱](https://www.youtube.com/watch?v=km0yT99eVTY)


Jetson Nano 동작
--
***

자 이제 Jetson에 라즈베리파이 카메라를 연결해주고 카메라를 이용한 물체인식 코드를 돌려 볼 차례이다.

터미널을 켜서
<blockquote class="u--startsWithDoubleQuote">sudo apt-get install git cmake</blockquote>
<pre><code>sudo apt-get install git cmake</code></pre>
를 실행한다.

깃허브에 있는 소스를 clone 해온다.
<pre><code>git clone https://github.com/dusty-nv/jetson-inference</code></pre>

clone이 완료가 되었다면 clone한 폴더로 이동하자
<pre><code>cd jetson-inference</code></pre>

그 다음 submodule update를 해준다.
<pre><code>git submodule update --init</code></pre>

build 라는 폴더를 하나 만들어주고, build로 이동
<pre><code>mkdir build
cd build</code></pre>

build 에서,
<pre><code>cmake ../
make
sudo make install</code></pre>를 입력하여 설치해주자

이제 실행할 준비가 되었다!

터미널에서
<pre><code>cd /jetson-inference/build/aarch64/bin</code></pre>로 이동해주고

imagenet-camera googlenet 실행
<pre><code>./imagenet-camera googlenet</code></pre>

실행하고 나서 심한 렉이 걸리거나, 화면이 멈춘다면 jetson의 전원을 한번 뽑아서 재부팅 해주면 된다.

imagenet-camera를 실행하였다면, 라즈베리파이 카메라로 잡히는 물체를 jetson이 어떤 사물인지 판단하여 알려준다.

필자는 jetson에게 가발판정을 받았다..T-T...
여러분은 그렇지 않길..

그럼 jetson이 인식한 내용을 보자

<div class="img img--fullContainer img--14xLeading" style="background-image: url({{ site.baseurl_posts_img }}JetsonNanoBananaCheck.png);"></div>
-바나나 모양 필통을 바나나로 인식했다. 가격이 의심되지만 이정도면 애교라고 생각한다.

<div class="img img--fullContainer img--14xLeading" style="background-image: url({{ site.baseurl_posts_img }}JetsonNanoLighterCheck.png);"></div>
-라이터를 잘 집어냈다. 역시 비싼 기계는 다르다.

<div class="img img--fullContainer img--14xLeading" style="background-image: url({{ site.baseurl_posts_img }}JetsonNanoMonitorCheck.png);"></div>
-모니터도 잘 간파했다.

이렇게 사물을 잘 판단하는 Jetson. 4차산업혁명의 리더라고 봐도 무방하겠다.

그렇다면 과연 자기 자신은 잘 판단할까?

<div class="img img--fullContainer img--14xLeading" style="background-image: url({{ site.baseurl_posts_img }}JetsonNanoSelfCheck.png);"></div>
..

....

자신을 그저 테이프 플레이어 정도로 밖에 생각하지 못하는 아쉬운 리더였다.

참고한 동영상 : [Jetson Nano :Vision Recognition Neural Network Demo](https://www.youtube.com/watch?v=k5pXXmTkPNM)
